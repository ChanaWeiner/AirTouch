/* global chrome */
import React, { useRef, useEffect, useState } from "react";
import Webcam from "react-webcam";
import { FilesetResolver, GestureRecognizer } from "@mediapipe/tasks-vision";
import "./App.css";

import Header from "./components/Header";
import Status from "./components/Status";
import Legend from "./components/Legend";
import PermissionScreen from "./components/PermissionScreen";
import { sendCommandToYouTube } from "./utils/youtube";
import { askGemini } from "./utils/api"; // ×”×™×™×‘×•× ×”×—×“×©

export default function App() {
  const webcamRef = useRef(null);
  const isSetupTab = window.location.search.includes("setup=true");

  // State
  const [appState, setAppState] = useState("loading"); 
  const [statusText, setStatusText] = useState("System Paused â¸ï¸");
  const [lastGesture, setLastGesture] = useState("-");
  
  // ××¦×‘×™× ××™×•×—×“×™× ×œ××™×§×¨×•×¤×•×Ÿ
  const [micState, setMicState] = useState("idle"); // 'idle', 'listening', 'thinking'
  
  // Refs
  const lastCommandTime = useRef(0);
  const lastSpeedToggleTime = useRef(0); // × ×¢×™×œ×” ××™×•×—×“×ª ×œ××”×™×¨×•×ª
  const recognizerRef = useRef(null);
  const intervalRef = useRef(null);

  useEffect(() => {
    if (isSetupTab) {
        setAppState("permission_needed");
        return;
    }
    const initSystem = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        stream.getTracks().forEach(t => t.stop());
        startMediaPipe();
      } catch (err) {
        setAppState("permission_needed");
      }
    };
    initSystem();
    return () => {
      if (intervalRef.current) clearInterval(intervalRef.current);
      if (recognizerRef.current) recognizerRef.current.close();
    };
  }, [isSetupTab]);

  const handlePermissionAction = async () => {
      if (isSetupTab) {
          try {
              const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
              stream.getTracks().forEach(t => t.stop());
              window.close(); 
          } catch (err) {
              alert("Permission denied.");
          }
      } else {
          if (typeof chrome !== "undefined" && chrome.tabs) {
              chrome.tabs.create({ url: "index.html?setup=true" });
          }
      }
  };

  const startMediaPipe = async () => {
    setStatusText("Loading AI Model... ğŸ§ ");
    try {
      const wasmUrl = chrome.runtime.getURL("wasm/");
      const vision = await FilesetResolver.forVisionTasks(wasmUrl);
      
      const recognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
          delegate: "GPU",
        },
        runningMode: "VIDEO",
      });
      
      recognizerRef.current = recognizer;
      startLoop(recognizer);
      
    } catch (error) {
      setAppState("error");
      setStatusText("Error: " + error.message);
    }
  };

  const startLoop = (recognizer) => {
    setAppState("running");
    setStatusText("Active! Show Hand âœ‹");

    intervalRef.current = setInterval(() => {
      if (webcamRef.current && webcamRef.current.video && webcamRef.current.video.readyState === 4) {
        const video = webcamRef.current.video;
        const results = recognizer.recognizeForVideo(video, Date.now());

        if (results.gestures.length > 0) {
          const gesture = results.gestures[0][0].categoryName;
          const confidence = results.gestures[0][0].score;
          setLastGesture(gesture);

          if (confidence > 0.6) {
            handleGestureControl(gesture);
          }
        } else {
           if (Date.now() - lastCommandTime.current > 1500) setLastGesture("-");
        }
      }
    }, 150);
  };

  const handleGestureControl = (gesture) => {
    const now = Date.now();
    
    // ×× ×”××™×§×¨×•×¤×•×Ÿ ×¢×•×‘×“ - ××ª×¢×œ××™× ××›×œ ×ª× ×•×¢×” ××—×¨×ª!
    if (micState !== "idle") return; 

    // ×§×™×¨×•×¨ ×›×œ×œ×™ ×œ×¤×§×•×“×•×ª ×¨×’×™×œ×•×ª (800ms)
    if (now - lastCommandTime.current < 800) return;

    let commandSent = false;

    switch (gesture) {
      case "Open_Palm": 
        setStatusText("â¸ï¸ Paused");
        sendCommandToYouTube("pause");
        commandSent = true;
        break;
      
      case "Closed_Fist": 
        setStatusText("â–¶ï¸ Playing");
        sendCommandToYouTube("play");
        commandSent = true;
        break;

      case "Victory": 
        // --- ×ª×™×§×•×Ÿ ×œ×‘×¢×™×™×ª ×”××”×™×¨×•×ª (Speed Toggle Fix) ---
        // ×× ×—× ×• ×‘×•×“×§×™× ×× ×¢×‘×¨×• 2 ×©× ×™×•×ª (2000ms) ××”×©×™× ×•×™ ×”××—×¨×•×Ÿ
        if (now - lastSpeedToggleTime.current > 2000) {
            setStatusText("âš¡ Toggling Speed...");
            sendCommandToYouTube("toggleSpeed"); 
            lastSpeedToggleTime.current = now; // ×¢×“×›×•×Ÿ ×–××Ÿ ×”× ×¢×™×œ×”
            commandSent = true;
        } else {
            // ×× ×œ× ×¢×‘×¨ ×–××Ÿ - ×× ×—× ×• ××ª×¢×œ××™× ××‘×œ ××¨××™× ×—×™×•×•×™ ×©×”×¤×§×•×“×” "× ×¢×•×œ×”"
            setStatusText("ğŸ”’ Speed Locked (Wait...)");
        }
        break;

      case "Thumb_Up": 
        setStatusText("â­ï¸ +10 Seconds");
        sendCommandToYouTube("seek", 10);
        commandSent = true;
        break;

      case "Thumb_Down": 
        setStatusText("â®ï¸ -10 Seconds");
        sendCommandToYouTube("seek", -10);
        commandSent = true;
        break;

      case "ILoveYou": 
        setStatusText("â­ï¸ Next / Skip");
        sendCommandToYouTube("skip");
        commandSent = true;
        break;

      case "Pointing_Up": 
        activateVoiceMode();
        // ×œ× ××¡×× ×™× commandSent ×›×“×™ ×œ× ×œ×”×¤×¢×™×œ ××ª ×”×§×™×¨×•×¨ ×”×¨×’×™×œ
        break;

      default: break;
    }

    if (commandSent) lastCommandTime.current = now;
  };

  // --- × ×™×”×•×œ ××™×§×¨×•×¤×•×Ÿ ××©×•×¤×¨ ---
  const activateVoiceMode = () => {
    if (micState !== "idle") return; // ×× ×™×¢×ª ×”×¤×¢×œ×” ×›×¤×•×œ×”
    
    setMicState("listening");
    setStatusText("ğŸ™ï¸ Listening... Speak Now!");
    sendCommandToYouTube("pause"); // ××©×ª×™×§ ××ª ×”×•×™×“××•

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'he-IL'; // ×¢×‘×¨×™×ª
    recognition.start();

    recognition.onresult = async (event) => {
      const transcript = event.results[0][0].transcript;
      
      // ×©×œ×‘ 1: ×–×™×”×™× ×• ×“×™×‘×•×¨, ×¢×•×‘×¨×™× ×œ××¦×‘ "×—×•×©×‘"
      setMicState("thinking");
      setStatusText("ğŸ§  Thinking: " + transcript);
      
      // ×©×œ×‘ 2: ×©×œ×™×—×” ×œ×©×¨×ª (Backend)
      const answer = await askGemini(transcript);
      
      // ×©×œ×‘ 3: ×”×¦×’×ª ×ª×©×•×‘×”
      setStatusText("ğŸ¤– AI: " + answer);
      
      // ×—×–×¨×” ×œ×©×’×¨×” ××—×¨×™ 5 ×©× ×™×•×ª
      setTimeout(() => { 
          setMicState("idle"); 
          setStatusText("Active! Show Hand âœ‹"); 
      }, 5000);
    };

    recognition.onerror = () => {
      // ×× ×”×™×™×ª×” ×©×’×™××” ××• ×©×§×˜ - ×¤×©×•×˜ ×—×•×–×¨×™× ××™×“ ×œ×©×’×¨×”
      setMicState("idle");
      setStatusText("Mic Cancelled / No Sound");
    };

    recognition.onend = () => {
        // ×× ×”×“×™×‘×•×¨ × ×’××¨ ×•×¢×“×™×™×Ÿ ×œ× ×§×™×‘×œ× ×• ×ª×•×¦××” (×œ××©×œ ×©×§×˜)
        if (micState === "listening") {
            setMicState("idle");
        }
    };
  };

  if (appState === "permission_needed") {
    return <PermissionScreen onAction={handlePermissionAction} isSetupTab={isSetupTab} />;
  }

  return (
    <div className="app-container">
      <Header />

      <div className="camera-wrapper">
        {appState === "loading" && <span style={{color: "white"}}>Starting Camera...</span>}
        {appState === "error" && <span style={{color: "red"}}>Error Loading AI</span>}
        {appState === "running" && (
            <>
                <Webcam
                    ref={webcamRef}
                    style={{
                        width: "100%", height: "100%", objectFit: "cover", transform: "scaleX(-1)",
                        opacity: micState !== "idle" ? 0.3 : 1, // ×¢××¢×•× ×›×©×”××™×§×¨×•×¤×•×Ÿ ×¢×•×‘×“
                        transition: "opacity 0.5s"
                    }}
                />
                
                {/* ××™×™×§×•×Ÿ ××™×§×¨×•×¤×•×Ÿ ×¢× ×§ ×›×©×× ×—× ×• ×‘××¦×‘ ×”××–× ×” */}
                {micState === "listening" && (
                    <div style={{position: "absolute", fontSize: "60px", animation: "pulse 1s infinite"}}>ğŸ™ï¸</div>
                )}
                {micState === "thinking" && (
                    <div style={{position: "absolute", fontSize: "60px", animation: "spin 1s infinite"}}>â³</div>
                )}

                <div className="overlay-text">
                    ğŸ‘ï¸ {lastGesture}
                </div>
            </>
        )}
      </div>

      {/* ×”×¡×˜×˜×•×¡ ××§×‘×œ ×¦×‘×¢ ×©×•× ×” ×× ×× ×—× ×• ×‘××¦×‘ ××™×§×¨×•×¤×•×Ÿ */}
      <div style={{
          backgroundColor: micState !== "idle" ? "#e3f2fd" : (appState === "running" ? "#e8f5e9" : "#eee"),
          color: micState !== "idle" ? "#1565c0" : (appState === "running" ? "#2e7d32" : "#777"),
          padding: "6px", borderRadius: "6px", fontWeight: "bold", 
          margin: "8px 0",
          border: "1px solid #ddd",
          fontSize: "13px",
          minHeight: "20px"
      }}>
          {statusText}
      </div>
      
      <Legend isActive={appState === "running" && micState === "idle"} />

    </div>
  );
}